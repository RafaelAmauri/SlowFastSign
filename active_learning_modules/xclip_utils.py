import os
import json
import numpy as np

from PIL import Image
from collections import defaultdict


def parseAnnotationFile(subsetPath: str, mode: str) -> dict:
    """Parses the entire annotation file
    #TODO Finish the description

    Args:
        subsetPath (str): The path to the subset that 
        mode       (str): The split that should be parsed. Options = ["train", "test", "]

    Returns:
        dict: _description_
    """

    annotationFilePath = os.path.join(subsetPath, f"phoenix-2014-multisigner/annotations/manual/{mode}.corpus.csv")

    with open(annotationFilePath, "r") as f:
        lines  = f.readlines()
        del lines[0]
    
    groundTruthByVideoPath = {}
    for line in lines:
        parts                = line.split("|")
        currentVideo         = parts[0]
        currentVideoFullPath = os.path.join(f"{subsetPath}/phoenix-2014-multisigner/features/fullFrame-256x256px/{mode}", f"{currentVideo}/1")
        
        currentGloss = parts[-1]
        currentGloss = currentGloss.rstrip("\n")
        
        groundTruthByVideoPath[currentVideoFullPath] = currentGloss


    return groundTruthByVideoPath


def getKeyFramesFromFolder(path: str, nFrames: int) -> list:
    """Gets nFrames from the video stored in a given path. The chosen frames are linearly spaced, meaning the distance
    between two chosen frames is the same. For example, if there are 50 frames in the path and nFrames = 3, the chosen frames will be [0, 24, 49].

    Args:
        path (str): The path to the folder containing the frames.
        nFrames (int): How many frames to choose.

    Returns:
        list: A list containing all the chosen frames.
    """
    files = os.listdir(path)
    files.sort()

    frames = []
    for file in files:
        img = np.array(Image.open(os.path.join(path, file)))
        
        frames.append(img)

    indices   = np.linspace(0, len(frames)-1, num=nFrames, dtype=np.int32)
    keyFrames = [ frames[idx] for idx in indices]

    return keyFrames


def parseInformativenessRanking(filePath: str):
    with open(filePath, "r") as f:
        rankings = json.load(f)

    
    return rankings


def parseSlowFastSignPredictionsFile(predictionsFilePath: str, unlabeledSubsetPath: str) -> dict:
    """Parses the prediction file and returns a dictionary containing what was the
    full prediction for each video.

    Args:
        predictionsFilePath (str): The path to the prediction file.
        unlabeledSubsetPath (str): The path to the unlabeled subset.

    Returns:
        dict: A dictionary mapping the glosses predicted for each video. It is a dict(videoPath: "predicted gloss")
    """
    # The glosses generated by SlowFastSign for each video in the
    # unlabeled pool are stored like this:
    
    # 31March_2010_Wednesday_tagesschau_default-3 1 0.00 0.01 IN-KOMMEND
    # 31March_2010_Wednesday_tagesschau_default-3 1 0.02 0.03 KOMMEN
    # 31March_2010_Wednesday_tagesschau_default-3 1 0.03 0.04 TIEF
    # 31March_2010_Wednesday_tagesschau_default-3 1 0.04 0.05 KOMMEN
    # 31March_2010_Wednesday_tagesschau_default-3 1 0.05 0.06 __OFF__

    # 31March_2010_Wednesday_tagesschau_default-9 1 0.00 0.01 IN-KOMMEND
    # 31March_2010_Wednesday_tagesschau_default-9 1 0.01 0.02 SONNTAG
    # 31March_2010_Wednesday_tagesschau_default-9 1 0.02 0.03 WETTER
    # 31March_2010_Wednesday_tagesschau_default-9 1 0.03 0.04 __OFF__


    # For each folder containing a video, there are several lines, each with an individual word.
    # We have to concatenate these words into a single list, so they can be easily passed over to the X-Clip text processor.
    with open(predictionsFilePath, "r") as f:
        lines            = f.readlines()
        glossesByFolder = defaultdict(str)

        for line in lines:
            # Split the line by space to extract the parts.
            parts           = line.split(" ")
            videoName       = parts[0]
            predictedWord   = parts[-1].rstrip("\n")

            glossesByFolder[videoName] += f"{predictedWord} "
        
        # Store the final gloss in the dictionary with the video path as the key instad of the folder name. Makes it easier for X-Clip to find the video this way.
        glossesByVideoPath = dict()
        for videoName, generatedGloss in glossesByFolder.items():
            generatedGloss = generatedGloss.rstrip(" ") # Remove trailing space after concatenating the last gloss. += f"{predictedWord} does that."
            videoPath      = os.path.join(f"{unlabeledSubsetPath}/phoenix-2014-multisigner/features/fullFrame-256x256px/test", f"{videoName}/1") # Switch just the folder name for the full video path.

            glossesByVideoPath[videoPath] = generatedGloss
    

    return glossesByVideoPath